name: Citibike Demand Forecasting Pipeline
on:
  # Schedule the workflow to run weekly on Sunday at 1:00 AM UTC
  schedule:
    - cron: '0 1 * * 0'
  
  # Allow manual triggering from GitHub UI
  workflow_dispatch:
    inputs:
      forecast_months:
        description: 'Number of months to forecast'
        default: '4'
        required: true
      window_size:
        description: 'Window size for time series features'
        default: '672'
        required: true
jobs:
  train_and_forecast:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Check for .env file
        run: |
          if [ -f ".env" ]; then
            echo ".env file exists and will be used"
            # Print keys in .env without values for verification
            echo "Keys found in .env file:"
            grep -o '^[^=]*' .env
          else
            echo "WARNING: .env file not found in repository"
          fi
      
      - name: Set up AWS credentials from .env
        run: |
          # Extract AWS credentials from .env file
          if [ -f ".env" ]; then
            # Source AWS credentials from .env file
            echo "Setting up AWS credentials from .env file"
            
            # Create AWS config directory
            mkdir -p ~/.aws
            
            # Extract credentials from .env and create AWS config files
            AWS_ACCESS_KEY_ID=$(grep AWS_ACCESS_KEY_ID .env | cut -d '=' -f2)
            AWS_SECRET_ACCESS_KEY=$(grep AWS_SECRET_ACCESS_KEY .env | cut -d '=' -f2)
            AWS_DEFAULT_REGION=$(grep AWS_DEFAULT_REGION .env | cut -d '=' -f2 || echo "us-east-1")
            
            # Create credentials file
            cat > ~/.aws/credentials << EOF
            [default]
            aws_access_key_id = $AWS_ACCESS_KEY_ID
            aws_secret_access_key = $AWS_SECRET_ACCESS_KEY
            EOF
            
            # Create config file
            cat > ~/.aws/config << EOF
            [default]
            region = $AWS_DEFAULT_REGION
            EOF
            
            # Test AWS configuration (listing S3 buckets without showing output)
            echo "Testing AWS configuration"
            aws s3 ls >/dev/null 2>&1 && echo "AWS credentials are working" || echo "Failed to connect to AWS"
          else
            echo "No .env file found, skipping AWS credential setup"
          fi
      
      - name: Update dynamic parameters
        run: |
          # Only update parameters that can be changed in the workflow
          if [ ! -z "${{ github.event.inputs.window_size }}" ]; then
            # If WINDOW_SIZE already exists in .env, update it
            if grep -q "WINDOW_SIZE=" .env; then
              sed -i "s/WINDOW_SIZE=.*/WINDOW_SIZE=${{ github.event.inputs.window_size }}/" .env
            else
              # Otherwise, add it
              echo "WINDOW_SIZE=${{ github.event.inputs.window_size }}" >> .env
            fi
          fi
          
          if [ ! -z "${{ github.event.inputs.forecast_months }}" ]; then
            # If FORECAST_MONTHS already exists in .env, update it
            if grep -q "FORECAST_MONTHS=" .env; then
              sed -i "s/FORECAST_MONTHS=.*/FORECAST_MONTHS=${{ github.event.inputs.forecast_months }}/" .env
            else
              # Otherwise, add it
              echo "FORECAST_MONTHS=${{ github.event.inputs.forecast_months }}" >> .env
            fi
          fi
          
          # Show the updated parameters
          echo "Dynamic parameters after update:"
          grep -E 'WINDOW_SIZE=|FORECAST_MONTHS=' .env || echo "Parameters not found"
      
      - name: Run training pipeline
        run: |
          python src/pipelines/train_models_pipeline.py
      
      # Store artifacts the alternative way
      - name: Save artifacts
        if: always()
        run: |
          # Create an artifact directory
          mkdir -p artifacts
          
          # Copy metrics files if they exist
          if [ -d "metrics" ]; then
            mkdir -p artifacts/metrics
            cp -r metrics/* artifacts/metrics/ || echo "No metrics files found"
          fi
          
          # Copy HTML files
          cp *.html artifacts/ || echo "No HTML files found"
          
          # Copy forecast CSV
          cp feb_may_2025_forecast.csv artifacts/ || echo "No forecast CSV found"
          
          # List what we're going to upload
          echo "Files prepared for upload:"
          find artifacts -type f | sort

      # Use a direct reference to the action
      - name: Upload all artifacts
        uses: actions/upload-artifact@c7d193f32edcb7bfad88892161225aeda64e9392
        with:
          name: forecast-artifacts
          path: artifacts
